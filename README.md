# Alzheimer's Disease Classification & Explainable AI
This repository showcases a machine learning project to classify stages of Alzheimer's Disease using demographic, lifestyle, medical, and cognitive data.  
The project focuses not only on prediction accuracy, but also on explaining model decisions using multiple state-of-the-art explainability methods: **SHAP, LIME, Anchor, and QLattice**.

---

## Project Overview
- **Goal**: Predict Alzheimer's Disease diagnosis stage from patient data.
- **Methods**:
  - Data cleaning and exploration (EDA)
  - Model training (e.g., XGBoost, Random Forest, etc.)
  - Model explainability: SHAP, LIME, Anchor explanations, QLattice modeling
- **Dataset**: Alzheimer's Disease Dataset by Rabie El Kharoua (2024) on Kaggle (2,149 patients aged 60â€“90).

This project demonstrates:
âœ… Transfer learning & ensemble models  
âœ… Multiple explainability techniques  
âœ… Professional, modular project structure for reproducibility


## ðŸ“‚ Project Structure
```plaintext
alzheimers-xai-ml/
â”œâ”€â”€ data/                    # (empty or small sample CSVs only)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ alzxai.ipynb         # ðŸ““ Main notebook: full EDA, modeling, explainability
â”œâ”€â”€ src/                     # ðŸ›  Reusable helper modules
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ eda_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ explainability_utils.py                
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md                # ðŸ“– This file
â””â”€â”€ .gitignore
